% -*- compile-command: "latexmk -pdf notes.tex" -*-
\documentclass{article}

\input{template}
\usepackage{cleveref}

\title{Intro to Real Analysis}
\author{Sam Price}

\begin{document}

\maketitle

\section{Basic Set Theory}
Let $A$, $B$, $C$ be sets (all subsets of some set $X$).
Note the operations of intersection, union, set difference and complement being defined as:
\begin{align}
  A \union B &= \set{x \in X : x \in A \lor x \in B}\\
  A \intersect B &= \set{x \in X : x \in A \land x \in B}\\
  A \setminus B &= \set{x \in X : x \in A \land x \notin B}\\
  A^{\complement} &= \set{x \in X : x \notin A}
\end{align}

and with this, we see the commutative, associative and distributive properties as such:
\begin{align}
  A \union B &= B \union A\\
  A \union (B \union C) &= (A \union B) \union C\\
  A \intersect B &= B \intersect A\\
  A \intersect (B \intersect C) &= (A \intersect B) \intersect C\\
  A \intersect (B \union C) &= (A \intersect B) \union (A \intersect C)\\
  A \union (B \intersect C) &= (A \union B) \intersect (A \union C)
\end{align}

De Morgan's Laws describe how the complement distributes:
\begin{align}
  {(A \union B)}^{\complement} &= A^{\complement} \intersect B^{\complement}\\
  {(A \intersect B)}^{\complement} &= A^{\complement} \intersect B^{\complement}
\end{align}

\subsection{Intervals}
For integral (or over $\Q$) intervals, marked $n \le x \le m$ for any integers $n, m$ it
is constructed as (where $\le$ and $<$ can be switched with the normal ideas):
\begin{equation}
  n \le x \le m = \set*{x \in \Z : n \le x \le m}
\end{equation}

For intervals on $R$, we see (where $x \le y$)
\begin{align*}
  (x, y) &= \set*{a \in \R : x < a < y}\\
  [x, y] &= \set*{a \in \R : x \le a \le y},
\end{align*}

and with half-open intervals being created intuitively.
While rational intervals can be defined as above, we also can see definitions by
intersections of sets with real intervals, for example $\Q \intersect (-\sqrt{2}, \sqrt{2})$.

\section{The Real Numbers ($\R$)}
The real numbers, also known as the continuum, is what we generally think of when we describe arbitrary
numbers, and is quite intuitive at first glance. After all, $\N$ and $\Z$ seem like they are obviously ``real'',
and the rationals are constructed in a super simplistic and inobtrusive manner.
With $\R$, you could simply describe it as ``filling in'' the gaps in $\Q$. While that would be a technically \textit{accurate}
definition, but would no
t be particularly precise since there isn't any rigorous manner in what it means to be irrat
ional.

The construction of $\R$ by Dedekind cuts is quite nice, and is made as follows:
A Dedekind cut $A|B$ is the separation of $\Q$ into two sets ($A$ and $B$) such that
$A \union B = \Q$ and $A \ne \emptyset$. For all $a \in A$, $a < b$ for all $b \in B$, and that $A$ has no \textit{least upper bound}.
What this means is that there is no $x \in \Q$ such that $x \ge a, \forall a \in A$ \textit{and} there is no number
smaller that said $x$ that also satisfies said expression. Since $B$ can be determined by $A$, a cut can be written as simply $A$.
If $B$ has some smallest element, then the cut refers to that smallest rational number in $B$. Otherwise, the cut \textit{is}
the irrational number, which might be unintuitive at first.

A great example of a cut is $A = \Q \intersect (-\infty, \sqrt{2})$. The reason this cut refers to $\sqrt{2}$ is that there
are infinitely many rational numbers that can approximate $\sqrt{2}$ from both above and below, and as such that cut $A$ \textit{is}
the positive real number $x$ such that $x^{2} = 2$.

\subsection{Fields and $\Q$}
A field $F$ is a specific type of group (a la abstract algebra), where there are
two operations ``multiplication'' and ``addition''
(\ $\cdot$ and $+$) that are associative as well as having identity elements in
$F$ and inverses (for nonzero values for $\cdot$).
Letting $a \in F$, the multiplicative identity is denoted $a\inv$ for $a \ne 0$
and the additive identity is $-a$.
Therefore, we have
\begin{align*}
  a \cdot a\inv &= 1\\
  a + (-a) = 0
\end{align*}

and note that subtraction and division are defined as
\begin{align*}
  a \div b &= a \cdot b\inv\\
  a - b &= a + (-b)
\end{align*}

As such, we see that $\Q$ is one such field, where the underlying
set is
\begin{equation}
  \Q = \set*{\dfrac{p}{q} : p, q \in \Z, q \ne 0, \gcd(p, q) = 1}
\end{equation}

\begin{prop}\label{prop:prop1}
 An integer is even only if its square is even.
\end{prop}
\begin{proof}
  By way of contraposition, let $m$ be an odd integer such that
  $m = 2k+1$ for some $k \in \Z$. Squaring $m$, we find that:
  \begin{equation}
    m^{2} = {(2k + 1)}^{2} = 4k^{2} + 4k + 1 = 2(2k^{2} + 2k) + 1.
  \end{equation}
  Since $m^{2}$ is odd, we can then say with certainty (by the contrapositive)
  that $m^{2}$ may only be even if $m$ itself is even.
\end{proof}

\begin{thm}
  $\sqrt{2} \notin \Q$.
\end{thm}
\begin{proof}
  Assume for the sake of contradiction that $\sqrt{2} \in \Q$.
  Since $\sqrt{2} \in \Q$, there exist integers $m, n$ such that $n \ne 0$
  and $\sqrt{2} = m/n$. Without loss of generality, we may assume that
  $m$ and $n$ are relatively prime.

  Isolating $m$, we find that
  \begin{equation*}
    m^{2} = 2n^{2}.
  \end{equation*}
  Since $m^{2}$ is even, we know that $m$ must also be even (Proposition~\ref{prop:prop1})
  and therefore that $m = 2k$ for some integer $k$.
  Similarly, we find that $n^{2} = {(2k)}^{2}/2$, which
  also means that $n$ is even as well.
  This is a contradiction however, as $n$ and $m$ may not both be even, which
  invalidates the assumption $\sqrt{2} \notin \Q$.
\end{proof}

\subsection{Orderings}

An order on a field $\F$ is some $P \subseteq F$ such that
for all $a, b \in P$, $a + b \in P$ and $a \cdot b \in P$.
We say that some $a < b$ if $b - a \in P$.

\begin{prop}\label{prop:ordered-field-properties}
  In an ordered field $\F$ with elements $a, b, c \in \F$:
  \begin{itemize}
          \item $a < b \implies a + c < b + c$.
          \item If $a < b$ and $b < c$, then $a < c$.
          \item If $a < b$ and $0 < c$, then $ac < bc$.
          If $c < 0$, then $bc < ac$.
          \item If $a \ne 0$, then $0 < a^{2}$
  \end{itemize}
\end{prop}

Here we define a special function (called $\abs{\cdot}$)
\begin{equation}\label{eq:abs-value}
  \abs{x} = \begin{cases}
              \ x& \textrm{if } x \ge 0\\
              -x& \textrm{else}
            \end{cases}
\end{equation}

Properties of $\abs{\cdot}$:
\begin{itemize}
        \item $\abs{x} \ge 0$ with equality iff $x = 0$.
        \item $x = \abs{-x}$.
        \item $-\abs{x} \le a \le \abs{x}$.
        \item $\abs{xy} = \abs{x}\abs{y}$.
        \item If $y \ne 0$, $\abs{\frac{x}{y}} = \frac{\abs{x}}{\abs{y}}$.
        \item $\abs{x} \le y \implies \abs{x} \le \abs{y}$
        \item $\abs{x + y} \le \abs{x} + \abs{y}$.
        \item $\abs{\abs{x} - \abs{y}} \le \abs{x - y}$.
\end{itemize}


\section{Sequences}

\begin{defn}{Convergent Sequence}{conv-seq}
  A sequence $(a_{n})$ converges to $a \in \R$ if for all $\eps > 0$, there exists some $N \in \N$
  where for all $n > N$
  \[
    \abs*{a_{n} - a} < \eps.
  \]
\end{defn}
\begin{defn}{Cauchy Sequence}{cauchy-seq}
  A sequence $(a_{n})$ is ``Cauchy'' if for all $\eps > 0$, there exists some $N \in \N$
  where for all $m, n > N$
  \[
    \abs*{a_{m} - a_{n}} < \eps.
  \]
\end{defn}

\begin{thm}[Algebraic Limit Theorem]
  Let $(a_{n}) \to a$, $(b_{n}) \to b$ and $c \in \R$.
  Then:
  \begin{itemize}
    \item $(a_{n} + b_{n}) \to a + b$.
    \item $(a_{n} \cdot b_{n}) \to ab$.
    \item $(ca_{n}) \to ca$.
    \item $(c + a_{n}) \to c + a$.
    \item $\parens*{\dfrac{a_{n}}{b_{n}}} \to \dfrac{a}{b}$, given $b \ne 0$ and $\forall n \in \N, b_{n} \ne 0$.
  \end{itemize}

\end{thm}

\begin{thm}[Bolzano-Weierstrass]
  Every bounded sequence has a convergent subsequence.

  \begin{proof}
    Let $(x_{n})$ be a bounded sequence.
    Thus, there exist $a_{1}, b_{1} \in \R$ such that for all $n \in \N$
    \[
      a_{1} \le x_{n} \le b_{1}.
    \]

    Consider the interval $[a_{1}, b_{1}]$, and split it into two equally-sized intervals
    At least of these intervals must contain infinitely many terms of $(x_{n})$.
    This interval will be referred to as $[a_{2}, b_{2}]$.
    Repeatedly doing this, we find that for all $n$, $[a_{n}, b_{n}]$ contains infinitely many terms.
    This infinite descent of intervals shows that
    \[
      [a_{1}, b_{1}] \supset [a_{2}, b_{2}] \supset \cdots \supset [a_{n}, b_{n}] \supset \cdots
    \]

    Define a subsequence of $(x_{n})$ by the following:
    \[
      x_{n_{k}} \textrm{ is any term from } [a_{n}, b_{n}] \textrm{ so long as } n_{k} \textrm { is greater than its predecessors}.
    \]

    For each $k$, we find
    \[
      a_{k} \le x_{n_{k}} \le b_{k}.
    \]

    In fact, we see by the nested intervals that
    \[
      a_{1} \le \cdots \le a_{k} \le \cdots \le b_{k} \le \cdots \le b_{1}.
    \]

    Thus, we find the sequence
    \[
      \set{a_{1}, a_{2}, \ldots, a_{k}, \ldots}
    \]
    is monotonically increasing and bounded.
    Thus, by the monotone convergence theorem, this sequence $(a_{n})$ converges.
    Similarly, $(b_{n})$ is monotonically decreasing and thus also converges.
    In fact, both of these sequences converge to the same value $r \in \R$.
    Applying the Squeeze Theorem to this, we find our subsequence $x_{n_{k}}$ also converges to this value,
    thus our convergent subsequence is found.
  \end{proof}
\end{thm}

\begin{defn}{Cauchy Sequence}{}
  A sequence $(a_{n})$ is considered \emph{Cauchy} if
  \[
    \forall \eps > 0, \exists N \in \N, \forall m,n > N
  \]
  there is
  \[
    \abs*{a_{m} - a_{n}} < \eps.
  \]
\end{defn}

\begin{ex}[Cauchy Test 1]
  Let $a_{n} = 7 + \frac{1}{n}$ and $\eps > 0$.
  Choose $N$ such that
  \[
    \frac{1}{N} < \frac{\eps}{2}.
  \]

  Then, we can see for all $m, n > N$ and $m > n$ that
  \begin{align*}
    \abs*{a_{m} - a_{n}} &= \abs*{7 + \frac{1}{m} - \parens*{7 + \frac{1}{n}}}\\
    &= \abs*{\frac{1}{m} - \frac{1}{n}}\\
    &\le \abs*{\frac{1}{m}} + \abs*{\frac{1}{n}}\\
    &< 2\frac{1}{n} < 2\frac{1}{N} < \eps.
  \end{align*}
\end{ex}

\begin{defn}[Series]
  A series is an expression
  \[
    \sum_{n = 1}^{\infty}a_{n} = a_{1} + a_{2} + \cdots + a_{k} + \cdots
  \]

  We say a series converges if and only if the sequence of ``partial sums'' (described next) converges.
  A partial sum (or a $k$\textsuperscript{th} partial sum) is an element
  \[
    s_{k} = \sum_{n = 1}^{k}a_{n}.
  \]
\end{defn}
\begin{prop}
  If $\sum_{n \in \N} a_{n} = \alpha$ and $\sum_{n \in \N} b_{n} = \beta$, then
  \begin{itemize}
    \item $\sum_{n \in \N} (a_{n} + b_{n}) = \alpha + \beta$.
    \item For any $c \in \R$, then $\sum_{n \in \N} (ca_{n}) = c\alpha$.
  \end{itemize}
\end{prop}

\begin{prop}
  If $(a_{n}) \not\to 0$, then $\sum a_{n}$ diverges.
  \begin{proof}
    We prove the contrapositive. Let $\sum a_{n}$ converge to $\alpha$ and the partial sums be $(s_{n}) \to \alpha$.
    Since $(s_{n})$ converges, it must also be Cauchy. For any $\eps > 0$, and there exists $N \in \N$ where $m > n > N$
    necessitates
    \[
      \abs*{s_{n} - s_{m}} < \eps.
    \]
    Thus, taking $m = n + 1$, we find $\abs*{a_{n + 1}} < \eps$. Since this is true for every $n > N$, the sequence must converge to 0.
  \end{proof}
\end{prop}
\begin{thm}
  The harmonic series
  \[
  \sum_{n = 1}^{\infty}\frac{1}{n}
  \]
  diverges.
\end{thm}

\begin{prop} Assume $0 \le a_{n} \le b_{n}$ for all $n \in \N$. Then,
  \begin{itemize}
    \item If $\sum_{n \in \N} b_{n}$ converges, then $\sum_{n \in \N} a_{n}$ converges.
    \item If $\sum_{n \in \N} a_{n}$ diverges to $\infty$, then $\sum_{n \in \N} b_{n}$ diverges to $\infty$.
  \end{itemize}
\end{prop}

\begin{prop}[Alternating Series Test]
  Let $(a_{n})$ be a monotone decreasing sequence with $(a_{n}) \to 0$.
  Then,
  \[
    \sum_{n = 1}^{\infty}\parens*{-1}^{n + 1}a_{n}
  \]
  converges.
  \begin{proof}
    Consider $(s_{2n})$ and $(s_{2n + 1})$, the sequences of partial sums of appropriate sizes.
    Note that
    \[
      s_{2n} = (a_{1} - a_{2}) + (a_{3} - a_{4}) + \cdots + (a_{2n - 1} - a_{2n})
    \]
    and therefore $(s_{2n})$ is monotone increasing.
    Now, we see
    \[
      s_{2n} = a_{1} - (a_{2} - a_{3})  - (a_{4} - a_{5}) - \cdots - (a_{2n - 2} - a_{2n - 1}) - a_{2n}
    \]
    Thus, $s_{2n} < a_{1}$ for all $n$. We then seen $(s_{2n})$ is bounded and converges. Namely, $(s_{2n}) \to L$
    with
    \[
      0 \le L \le a_{1}.
    \]
    Looking at $s_{2n + 1}$, we see with similar manipulation that $(s_{2n + 1}) \to L'$.
    Using the algebraic limit theorem, we note that
    \[
      (s_{2n + 1} - s_{2n}) = (a_{2n + 1}) = L' - L.
    \]
    Since $(a_{2n + 1}) \to 0$, we know $L = L'$.
    Now, let $\eps > 0$. There exist $N_{1}, N_{2} \in \N$ such that
    \begin{align*}
      \abs*{s_{2n} - L} &< \eps \quad \forall n > N_{1}\\
      \abs*{s_{2n + 1 - L}} &< \eps \quad \forall n > N_{2}.
    \end{align*}
    For all $n > N = \max\{N_{1}, N_{2}\}$, we have
    \[
      \abs{s_{n} - L} < \eps \quad \forall n > N.
    \]
    As such, $(s_{n}) \to L$.
  \end{proof}
\end{prop}

\begin{defn}[Absolute and Conditional Convergence]\label{defn:absolute-conditional-convergence}
  A series is said to \emph{converge absolutely} if
  \[
    \sum_{n = 1}^{\infty}\abs*{a_{n}}
  \]
  converges. The series is \emph{conditionally convergent} if
  \[
    \sum_{n = 1}^{\infty}a_{n}
  \]
  converges but it is not \emph{absolutely} convergent.
\end{defn}

\begin{thm}[Riemann Rearrangement Theorem]\label{thm:riemann-rearrangement}
  Any conditionally convergent series can be rearranged such that for any $L \in R^{*}$ (the extended real line),
  the series converges to $L$.
\end{thm}

\section{Topology of $\R$}

\begin{defn}[$\eps$-neighborhood]\label{defn:epsilon-neighborhood}
  An $\eps$-neighborhood of a point $x \in \R$ is
  \[ (x - \eps, x + \eps) \]
  where $\eps$ is implicitly positive,
  and sometimes denoted $N_{\eps}(x)$, $\eps(x)$ or $V_{\eps}(x)$.
\end{defn}

\begin{defn}[Open Set]\label{defn:open-set}
  A set $A \subseteq R$ is considered \emph{open} if for all $x \in A$, there exists an $\eps > 0$ such that
  $N_{\eps}(x) \subseteq A$.
\end{defn}

\begin{defn}[Closed Set]\label{defn:closed-set}
  A set $A \subseteq R$ is considered \emph{closed} if its complement $A^{C}$ is open.
\end{defn}

\begin{thm}[Union of Closed Sets]\label{thm:union-closed-sets}
  If $\set{U_{\alpha}}_{\alpha \in \sS}$ is a class of closed sets, then
  \begin{itemize}
    \item $\ds\bigcap_{\alpha \in \sS}U_{\alpha}$ is closed.
    \item If $\abs{\sS} = n$ is finite, then $\ds\bigcup_{\alpha = 1}^{n}U_{\alpha}$ is closed.
  \end{itemize}
\end{thm}

\begin{prop}
  Every open set is a countable union of open intervals.
\end{prop}

\begin{defn}[Limit Point]\label{defn:limit-point}
  A point $x$ is a limit point of a set $A$ if there exist a sequence of points $a_{1}, a_{2}, \ldots \to x$ where each $a_{n} \in A \setminus \set{x}$.
\end{defn}

\begin{thm}[Closed iff contains limit points]\label{defn:closed-iff-limit-points}
  A set $A$ is closed if and only if it contains all of its limit points.
\end{thm}

\subsection{Covers and Subcovers}

\begin{defn}[Cover]\label{defn:cover}
  A \emph{cover} of a set $A$ is a class $\sS$ such that
  \[ A \subseteq \bigcup_{\alpha \in \sS}U_{\alpha}. \]
  If there is a finite subset $\sF \subseteq \sS$ where this holds, then $\set{U_{\alpha}}_{\alpha \in \sF}$
  is called a \emph{finite subcover}.
\end{defn}

\begin{defn}[Open Cover]\label{defn:open-cover}
  A cover $\sS$ is called an \emph{open cover} if each set in $\sS$ is open.
\end{defn}

\subsubsection{Compactness}

\begin{defn}[Compactness]\label{defn:compact-set}
  A set $A$ is \emph{compact} if every open cover of $A$ has a finite subcover.
\end{defn}
This is perhaps the most important definition of the next ten years, and it is (without~\nameref{thm:heine-borel}) very difficult
to prove a set $A$ is compact.

\begin{thm}[Heine-Borel]\label{thm:heine-borel}
  For a set $A \subseteq \R$, the following are equivalent
  \begin{itemize}
    \item $A$ is compact.
    \item $A$ is closed and bounded.
    \item For any sequence $(a_{n})$ in $A$, there is a subsequence $(a_{n_{k}})$ that converges to a point in $A$.
  \end{itemize}
\end{thm}

\section*{Derivatives \& Integrals}

% Need to define: Partition, Riemann-Darboux Sum
% Prove add-1 point to partition -> better estimate

\begin{defn}[Riemann-Darboux Sum]
  If $f \from I \to \R$ bounded and $P$ is a partition of $I$, then the upper and lower Riemann sums are denoted:
  \[ U(f) = \inf U(f, P) \]
  \[ L(f) = \sup L(f, P) \]
  and $f$ is integrable if $U(f) = L(f)$.
\end{defn}

\begin{defn}[Integrable Function]
  Note that
\end{defn}

\end{document}
